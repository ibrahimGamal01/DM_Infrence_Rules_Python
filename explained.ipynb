{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This program takes a list of English sentences and translates them into logical expressions. It\n",
    "## uses a set of predefined rules to match the sentences to logical expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module have funs to search a str for match\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace '{Q}' with '(?P<Q>.+?)', which means 'match 1 or more characters, and call it Q'\n",
    "# name_group function is used in the Rule function to create named groups in regular expressions \n",
    "# that are used to match patterns in the input text. The function takes a regular expression pattern as\n",
    "# input and replaces any instances of {} with (?P<{}>.+?),\n",
    "# which creates a named group with the specified name. This makes it easier to extract the values of these groups later on.\n",
    "def name_group(pat):\n",
    "    return re.sub('{(.)}', r'(?P<\\1>.+?)', pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Rule** takes a string and a list of patterns as input. It returns a tuple containing the output string and a list of patterns with the named groups replaced.\n",
    "#produce output if the input matches any pattern\n",
    "def Rule(output, *patterns): \n",
    "    return (output, [name_group(pat) + '$' for pat in patterns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match whole words in the input text, \\b boundary metacharacters to match full word as an entity\n",
    "# used in the negations list to match negations in the input text.      \n",
    "def word(w):\n",
    "    return r'\\b' + w + r'\\b' # '\\b' matches at word boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    Rule('{P} ⇒ {Q}',         'if {P} then {Q}', 'if {P}, {Q}'),\n",
    "    Rule('{P} ⋁ {Q}',          'either {P} or else {Q}', 'either {P} or {Q}'),\n",
    "    Rule('{P} ⋀ {Q}',          'both {P} and {Q}'),\n",
    "    Rule('～{P} ⋀ ～{Q}',       'neither {P} nor {Q}'),\n",
    "    Rule('～{A}{P} ⋀ ～{A}{Q}', '{A} neither {P} nor {Q}'), \n",
    "    Rule('～{Q} ⇒ {P}',        '{P} unless {Q}'),\n",
    "    Rule('{P} ⇒ {Q}',          '{Q} provided that {P}', '{Q} whenever {P}', \n",
    "                               '{P} implies {Q}', '{P} therefore {Q}', \n",
    "                               '{Q}, if {P}', '{Q} if {P}', '{P} only if {Q}'),\n",
    "    Rule('{P} ⋀ {Q}',          '{P} and {Q}', '{P} but {Q}'),\n",
    "    Rule('{P} ⋁ {Q}',          '{P} or else {Q}', '{P} or {Q}'),\n",
    "    ]\n",
    "\n",
    "negations = [\n",
    "    (word(\"not\"), \"\"),\n",
    "    (word(\"cannot\"), \"can\"),\n",
    "    (word(\"can't\"), \"can\"),\n",
    "    (word(\"won't\"), \"will\"),\n",
    "    (word(\"ain't\"), \"is\"),\n",
    "    (\"n't\", \"\"), # matches as part of a word: didn't, couldn't, etc.\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a sentence, a list rules, dictionary of definitions.\n",
    "# match the sentence against each rule, and returns the logic translation and the updated dictionary of definitions.\n",
    "#return the logic translation and  english def\n",
    "# اعتبرها الماين فنكنشن اللي بتشغل الرول والليترال\n",
    "def match_rules(sentence, rules, defs):\n",
    "    sentence = clean(sentence)\n",
    "    for rule in rules:\n",
    "        result = match_rule(sentence, rule, defs)\n",
    "        if result: \n",
    "            return result\n",
    "    return match_literal(sentence, negations, defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return logic transition and the dict of def if the match succed  \n",
    " ##If the sentence matche one of the rule's patterns, it returns the logic translation     \n",
    "def match_rule(sentence, rule, defs):\n",
    "    output, patterns = rule\n",
    "    for pat in patterns:\n",
    "        match = re.match(pat, sentence, flags=re.I)\n",
    "        if match:\n",
    "            groups = match.groupdict()\n",
    "            for P in sorted(groups): # Recursively apply rules to each of the matching groups\n",
    "                groups[P] = match_rules(groups[P], rules, defs)[0]\n",
    "            return '(' + output.format(**groups) + ')', defs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if No rule matched;  Add new proposition to defs. Handle negation       \n",
    "def match_literal(sentence, negations, defs):\n",
    "    polarity = ''\n",
    "    for (neg, pos) in negations:\n",
    "        (sentence, n) = re.subn(neg, pos, sentence, flags=re.I)\n",
    "        polarity += n * '～'\n",
    "    sentence = clean(sentence)\n",
    "    P = proposition_name(sentence, defs)\n",
    "    defs[P] = sentence\n",
    "    return polarity + P, defs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the old name for this sentence, if used before, or a new, unused name\n",
    "# This function takes a list of sentences and a width as input. It matches the rules against each\n",
    "# sentence and prints the results.\n",
    "def proposition_name(sentence, defs, names='PQRSTUVWXYZBCDEFGHJKLMN'):\n",
    "    inverted = {defs[P]: P for P in defs}\n",
    "    if sentence in inverted:\n",
    "        return inverted[sentence]                      # Find previously-used name\n",
    "    else:\n",
    "        return next(P for P in names if P not in defs) # Use a new unused name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove redundant whitespace; handle curly apostrophe and trailing comma/period    \n",
    "def clean(text): \n",
    "    return ' '.join(text.split()).replace(\"’\", \"'\").rstrip('.').rstrip(',')\n",
    "match_rule(\"If today is Tuesday, I have a test in english\",\n",
    "           Rule('{P} ⇒ {Q}', 'if {P}, {Q}'),\n",
    "           {})\n",
    "\n",
    "sentences = ''' if today is Tuesday, I have a test in english, it is Tuesday'''.split('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English: if today is Tuesday, I have a test in english, it is Tuesday. \n",
      "\n",
      "Logic: (P ⇒ Q)\n",
      "P: today is Tuesday\n",
      "Q: I have a test in english, it is Tuesday\n"
     ]
    }
   ],
   "source": [
    "#to make sure every str (input) at most width\n",
    "import textwrap\n",
    "#match rules against each sentence in txt and print result\n",
    "def logic(sentences, width=80): \n",
    "    for s in map(clean, sentences):\n",
    "        logic, defs = match_rules(s, rules, {})\n",
    "        print('\\n' + textwrap.fill('English: ' + s +'.', width), '\\n\\nLogic:', logic)\n",
    "        for P in sorted(defs):\n",
    "            print('{}: {}'.format(P, defs[P]))\n",
    "            \n",
    "logic(sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_rule(sentence, output, patterns, defs):\n",
    "    key = (output, tuple(patterns))  # Use a tuple of (output, tuple(patterns)) as the cache key\n",
    "    if key in match_rule.cache:\n",
    "        return match_rule.cache[key]\n",
    "    pattern_str = r'\\b' + '|'.join([f'(?P<P{i+len(patterns)}>{p})' for i, p in enumerate(output.split())] + [f'(?P<P{i}>{p})' for i, p in enumerate(patterns)]) + r'\\b'  # Use unique group names for each variable in output and patterns\n",
    "    groups = re.match(pattern_str, sentence)\n",
    "    if groups:\n",
    "        groups = groups.groupdict()\n",
    "        for i, P in enumerate(output.split()):\n",
    "            if f'P{i+len(patterns)}' in groups and P not in patterns:\n",
    "                groups[f'P{i+len(patterns)}'], defs = match_rule(sentence, output, patterns + [groups[f'P{i+len(patterns)}']], defs)\n",
    "        result = '(' + output.format(**groups) + ')', defs\n",
    "    else:\n",
    "        result = '', defs\n",
    "    match_rule.cache[key] = result\n",
    "    return result\n",
    "match_rule.cache = {}  # Initialize the cache as an empty dictionary\n",
    "\n",
    "def match_rules(sentence, rules, defs={}):\n",
    "    key = str((tuple(rules), defs))  # Use a string representation of (tuple(rules), defs) as the cache key\n",
    "    if key in match_rules.cache:\n",
    "        return match_rules.cache[key]\n",
    "    sentence = clean(sentence)\n",
    "    for rule in rules:\n",
    "        result, defs = match_rule(sentence, *rule, defs)\n",
    "        if result: \n",
    "            match_rules.cache[key] = result, defs\n",
    "            return result, defs\n",
    "    match_rules.cache[key] = None, defs\n",
    "    return None, defs\n",
    "match_rules.cache = {}  # Initialize the cache as an empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modus_ponens(P_Q, P):\n",
    "    P_Q = P_Q.strip('()')\n",
    "    P, Q = P_Q.split('⇒')\n",
    "    if P.strip() == P and Q.strip() == Q:\n",
    "        if P.strip() == P_Q.strip():\n",
    "            return Q.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothetical_syllogism(P_Q, Q_R):\n",
    "    P_Q = P_Q.strip('()')\n",
    "    Q_R = Q_R.strip('()')\n",
    "    P, Q = P_Q.split('⇒')\n",
    "    Q, R = Q_R.split('⇒')\n",
    "    if P.strip() == P and Q.strip() == Q and R.strip() == R:\n",
    "        if Q.strip() == Q_R.strip().split('⇒')[0].strip():\n",
    "            return P.strip() + ' ⇒ ' + R.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplification(P_and_Q):\n",
    "    P_and_Q = P_and_Q.strip('()')\n",
    "    P, Q = P_and_Q.split('⋀')\n",
    "    return P.strip() or Q.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjunction(P, Q):\n",
    "    return P.strip() + ' ⋀ ' + Q.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modus_tollens(P_Q, not_Q):\n",
    "    P_Q = P_Q.strip('()')\n",
    "    P, Q = P_Q.split('⇒')\n",
    "    if P.strip() == P and Q.strip() == Q:\n",
    "        if '～' + Q.strip() == not_Q.strip():\n",
    "            return '～' + P.strip()\n",
    "    return None\n",
    "\n",
    "def disjunctive_syllogism(P_or_Q, not_P):\n",
    "    P_or_Q = P_or_Q.strip('()')\n",
    "    P, Q = P_or_Q.split('⋁')\n",
    "    if '～' + P.strip() == not_P.strip():\n",
    "        return Q.strip()\n",
    "    elif '～' + Q.strip() == not_P.strip():\n",
    "        return P.strip()\n",
    "    return None\n",
    "\n",
    "def resolution(P, not_P):\n",
    "    if P.strip() == '～' + not_P.strip():\n",
    "        return ''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_rules(propositions):\n",
    "    for i, P in enumerate(propositions):\n",
    "        for j, Q in enumerate(propositions):\n",
    "            if i != j:\n",
    "                P_Q = match_rules(P + ' ⇒ ' + Q, rules, {})[0]\n",
    "                not_Q = '～' + Q.strip()\n",
    "                if P_Q and not_Q in propositions:\n",
    "                    # Modus Ponens\n",
    "                    result = modus_ponens(P_Q, P)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                Q_R = match_rules(Q + ' ⇒ ' + P, rules, {})[0]\n",
    "                if P_Q and Q_R:\n",
    "                    # Hypothetical Syllogism\n",
    "                    result = hypothetical_syllogism(P_Q, Q_R)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                if '⋁' in P:\n",
    "                    # Disjunctive Syllogism\n",
    "                    result = disjunctive_syllogism(P, not_Q)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                if '⋁' in Q:\n",
    "                    # Disjunctive Syllogism\n",
    "                    result = disjunctive_syllogism(Q, not_P=P)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                if '⋀' in P and '⋀' in Q:\n",
    "                    # Simplification\n",
    "                    result = simplification(P + ' ⋀ ' + Q)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                    # Conjunction\n",
    "                    result = conjunction(P, Q)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                not_P = '～' + P.strip()\n",
    "                if not_P in propositions:\n",
    "                    # Modus Tollens\n",
    "                    result = modus_tollens(Q_R, not_P)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                    # Disjunctive Syllogism\n",
    "                    result = disjunctive_syllogism(P, not_P=not_P)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "                    # Resolution\n",
    "                    result = resolution(P, not_P)\n",
    "                    if result:\n",
    "                        return result\n",
    "                    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propositions = ['today is Tuesday', 'I have a test in english, it is Tuesday']\n",
    "result = test_inference_rules(propositions)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
